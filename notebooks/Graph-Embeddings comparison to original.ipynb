{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detailed data can be downloaded here: http://snap.stanford.edu/conflict/conflict_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loading handcrafted features\n",
    "meta_features = {}\n",
    "meta_labels = {}\n",
    "with open(DATA_DIR+\"/detailed_data/handcrafted_features.tsv\") as fp:\n",
    "    for line in fp:\n",
    "        info = line.split()\n",
    "        meta_features[info[0]] = np.array(list(map(float, info[-1].split(\",\"))))\n",
    "        meta_labels[info[0]] = 1 if info[1] == \"burst\" else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loading the user, source, and target community embeddings for all examples\n",
    "with open(DATA_DIR + \"/detailed_data/full_ids.txt\") as fp:\n",
    "    ids = {id.strip():i for i, id in enumerate(fp.readlines())}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loading the post embeddings from the LSTM \n",
    "\n",
    "lstm_ids = pickle.load(open(DATA_DIR + \"/detailed_data/lstm_embeds-ids.pkl\",'rb'))\n",
    "lstm_ids = {id:i for i, id in enumerate(lstm_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeds = pd.read_csv('./prediction/detailed_data/all_embeds.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_embeds = pd.read_csv('./prediction/detailed_data/lstm_embeds.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loading preprocessed lstm data to ensure identical train/val/test splits\n",
    "train_data = pickle.load(open(DATA_DIR + \"/preprocessed_train_data.pkl\",'rb'))\n",
    "val_data = pickle.load(open(DATA_DIR + \"/preprocessed_val_data.pkl\",'rb'))\n",
    "test_data = pickle.load(open(DATA_DIR + \"/preprocessed_test_data.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattening the preprocessed LSTM data (no need for minibatching here....)\n",
    "def flatten(data):\n",
    "    ids, text, users, subreddits, lengths,sfs, labels = [], [], [], [], [], [], []\n",
    "    for batch in data:\n",
    "        bids, btext, busers, bsubreddits, blengths, bsfs, blabels = batch\n",
    "        ids.extend([x.decode('utf-8') for x in bids])\n",
    "        text.extend(btext.numpy().tolist())\n",
    "        users.extend(busers.numpy().tolist())\n",
    "        subreddits.extend(bsubreddits.numpy().tolist())\n",
    "        lengths.extend(blengths)\n",
    "        labels.extend(blabels)\n",
    "        sfs.extend(bsfs)\n",
    "    return (ids, text, users, subreddits, lengths, labels)\n",
    "flat_train_data = flatten(train_data)\n",
    "flat_val_data = flatten(val_data)\n",
    "flat_test_data = flatten(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_ids_parse = [(x.decode('utf-8'),y) for x,y in list(lstm_ids.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_ids = dict(lst_ids_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_X = np.stack([np.concatenate([meta_features[i], all_embeds[ids[i]], lstm_embeds[lstm_ids[i]]]) for i in flat_train_data[0]])\n",
    "val_X =  np.stack([np.concatenate([meta_features[i], all_embeds[ids[i]], lstm_embeds[lstm_ids[i]]]) for i in flat_val_data[0] if i in meta_features])\n",
    "test_X =  np.stack([np.concatenate([meta_features[i],all_embeds[ids[i]], lstm_embeds[lstm_ids[i]]]) for i in flat_test_data[0] if i in meta_features])\n",
    "\n",
    "train_Y = np.stack([meta_labels[i] for i in flat_train_data[0] if i in meta_features])\n",
    "val_Y =  np.stack([meta_labels[i] for i in flat_val_data[0] if i in meta_features])\n",
    "test_Y =  np.stack([meta_labels[i] for i in flat_test_data[0] if i in meta_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, n_jobs=100, random_state=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we run the Random Forest with only the metadata/handcrafted features...\n",
    "baseline_mod = RandomForestClassifier(n_estimators=500, n_jobs=100, random_state=0)\n",
    "# note that the first 263 features are the handcrafted ones... \n",
    "baseline_mod.fit(train_X[:, :263], train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6823914377654168\n"
     ]
    }
   ],
   "source": [
    "# For reference, on the authors server we get 0.682\n",
    "print(roc_auc_score(val_Y, baseline_mod.predict_proba(val_X[:, :263])[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6657555806104909"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_Y, baseline_mod.predict_proba(test_X[:, :263])[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, n_jobs=100, random_state=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# First we run the Random Forest with only the metadata/handcrafted features...\n",
    "ensemble_mod = RandomForestClassifier(n_estimators=500, n_jobs=100, random_state=0)\n",
    "# note that the first 263 features are the handcrafted ones... \n",
    "ensemble_mod.fit(train_X[:, :], train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7555938981870011"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(val_Y, ensemble_mod.predict_proba(val_X[:, :])[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('soc-redditHyperlinks-body.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emb = pd.read_csv('embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emb = df_emb.set_index('subreddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['post_id_cropped'] = df['POST_ID'].apply(lambda x: x[:-1] if len(x) == 7 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post_idx = df.set_index('post_id_cropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>-2.581650</td>\n",
       "      <td>4.197357</td>\n",
       "      <td>-0.414158</td>\n",
       "      <td>-4.637616</td>\n",
       "      <td>-1.270464</td>\n",
       "      <td>0.721880</td>\n",
       "      <td>3.302603</td>\n",
       "      <td>3.852562</td>\n",
       "      <td>0.082770</td>\n",
       "      <td>0.855891</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.309510</td>\n",
       "      <td>2.200328</td>\n",
       "      <td>-0.537800</td>\n",
       "      <td>-0.944857</td>\n",
       "      <td>-3.069158</td>\n",
       "      <td>3.882328</td>\n",
       "      <td>4.642304</td>\n",
       "      <td>-4.706831</td>\n",
       "      <td>-1.937072</td>\n",
       "      <td>6.749583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theredlion</th>\n",
       "      <td>-5.078587</td>\n",
       "      <td>3.187933</td>\n",
       "      <td>1.306380</td>\n",
       "      <td>3.390276</td>\n",
       "      <td>0.009027</td>\n",
       "      <td>2.208565</td>\n",
       "      <td>0.663524</td>\n",
       "      <td>-2.170339</td>\n",
       "      <td>-3.299234</td>\n",
       "      <td>4.855823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.704552</td>\n",
       "      <td>-1.988924</td>\n",
       "      <td>1.746807</td>\n",
       "      <td>1.682895</td>\n",
       "      <td>0.917564</td>\n",
       "      <td>-2.376134</td>\n",
       "      <td>1.840948</td>\n",
       "      <td>1.383271</td>\n",
       "      <td>-2.815420</td>\n",
       "      <td>-0.156633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inlandempire</th>\n",
       "      <td>1.787371</td>\n",
       "      <td>1.144207</td>\n",
       "      <td>-1.939735</td>\n",
       "      <td>-0.874147</td>\n",
       "      <td>-1.687357</td>\n",
       "      <td>-1.447701</td>\n",
       "      <td>-2.463367</td>\n",
       "      <td>0.047332</td>\n",
       "      <td>3.669208</td>\n",
       "      <td>-5.642140</td>\n",
       "      <td>...</td>\n",
       "      <td>1.381191</td>\n",
       "      <td>1.326390</td>\n",
       "      <td>1.959474</td>\n",
       "      <td>-0.830282</td>\n",
       "      <td>-8.217797</td>\n",
       "      <td>-0.690313</td>\n",
       "      <td>-2.515662</td>\n",
       "      <td>0.354737</td>\n",
       "      <td>-0.242708</td>\n",
       "      <td>-0.834380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>1.324327</td>\n",
       "      <td>2.414587</td>\n",
       "      <td>2.463422</td>\n",
       "      <td>1.304439</td>\n",
       "      <td>5.792188</td>\n",
       "      <td>2.861849</td>\n",
       "      <td>4.123739</td>\n",
       "      <td>1.847484</td>\n",
       "      <td>-2.223504</td>\n",
       "      <td>0.842010</td>\n",
       "      <td>...</td>\n",
       "      <td>2.977067</td>\n",
       "      <td>-0.718431</td>\n",
       "      <td>-0.049687</td>\n",
       "      <td>-0.443616</td>\n",
       "      <td>2.430853</td>\n",
       "      <td>-0.791676</td>\n",
       "      <td>0.064785</td>\n",
       "      <td>-1.367642</td>\n",
       "      <td>0.383723</td>\n",
       "      <td>5.842690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playmygame</th>\n",
       "      <td>3.036528</td>\n",
       "      <td>0.657404</td>\n",
       "      <td>1.333009</td>\n",
       "      <td>-2.353914</td>\n",
       "      <td>-3.739832</td>\n",
       "      <td>-1.316537</td>\n",
       "      <td>0.128526</td>\n",
       "      <td>0.776541</td>\n",
       "      <td>-3.212834</td>\n",
       "      <td>-0.607011</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.821251</td>\n",
       "      <td>-0.415504</td>\n",
       "      <td>-3.183492</td>\n",
       "      <td>3.704080</td>\n",
       "      <td>2.105642</td>\n",
       "      <td>-5.455093</td>\n",
       "      <td>1.901566</td>\n",
       "      <td>1.531182</td>\n",
       "      <td>-0.390700</td>\n",
       "      <td>4.803727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcchallenges</th>\n",
       "      <td>1.088152</td>\n",
       "      <td>-1.052172</td>\n",
       "      <td>-0.081496</td>\n",
       "      <td>0.599227</td>\n",
       "      <td>0.587108</td>\n",
       "      <td>-0.421348</td>\n",
       "      <td>-0.328897</td>\n",
       "      <td>-0.444257</td>\n",
       "      <td>0.726301</td>\n",
       "      <td>-0.338954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.529689</td>\n",
       "      <td>1.102415</td>\n",
       "      <td>-0.329409</td>\n",
       "      <td>0.948866</td>\n",
       "      <td>-0.232821</td>\n",
       "      <td>-1.136177</td>\n",
       "      <td>0.209243</td>\n",
       "      <td>0.079921</td>\n",
       "      <td>1.184984</td>\n",
       "      <td>-0.558518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoomies</th>\n",
       "      <td>0.745022</td>\n",
       "      <td>0.203817</td>\n",
       "      <td>-1.079956</td>\n",
       "      <td>-1.680853</td>\n",
       "      <td>1.577193</td>\n",
       "      <td>-0.841061</td>\n",
       "      <td>-0.916199</td>\n",
       "      <td>0.172354</td>\n",
       "      <td>0.699129</td>\n",
       "      <td>0.416368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186617</td>\n",
       "      <td>0.441517</td>\n",
       "      <td>1.469669</td>\n",
       "      <td>0.824215</td>\n",
       "      <td>1.754825</td>\n",
       "      <td>-0.493108</td>\n",
       "      <td>0.523124</td>\n",
       "      <td>0.050339</td>\n",
       "      <td>0.626424</td>\n",
       "      <td>-1.088371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asshole</th>\n",
       "      <td>-0.537883</td>\n",
       "      <td>-0.661029</td>\n",
       "      <td>0.098713</td>\n",
       "      <td>-0.808670</td>\n",
       "      <td>0.923758</td>\n",
       "      <td>-0.627248</td>\n",
       "      <td>-0.254959</td>\n",
       "      <td>0.508056</td>\n",
       "      <td>0.135096</td>\n",
       "      <td>-0.354623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117812</td>\n",
       "      <td>-0.571725</td>\n",
       "      <td>-0.966365</td>\n",
       "      <td>0.951634</td>\n",
       "      <td>0.411589</td>\n",
       "      <td>-0.488988</td>\n",
       "      <td>0.083463</td>\n",
       "      <td>1.102945</td>\n",
       "      <td>-1.133330</td>\n",
       "      <td>-0.873870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dildohero</th>\n",
       "      <td>-0.249038</td>\n",
       "      <td>-0.996826</td>\n",
       "      <td>0.725330</td>\n",
       "      <td>-0.713229</td>\n",
       "      <td>-0.866005</td>\n",
       "      <td>-0.326092</td>\n",
       "      <td>-0.751363</td>\n",
       "      <td>-1.660205</td>\n",
       "      <td>1.693578</td>\n",
       "      <td>-0.749767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024560</td>\n",
       "      <td>0.254378</td>\n",
       "      <td>0.024955</td>\n",
       "      <td>0.659600</td>\n",
       "      <td>0.813747</td>\n",
       "      <td>-1.120681</td>\n",
       "      <td>-0.736590</td>\n",
       "      <td>-0.005955</td>\n",
       "      <td>0.421525</td>\n",
       "      <td>-1.350236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ouija_irl</th>\n",
       "      <td>0.471297</td>\n",
       "      <td>-1.322305</td>\n",
       "      <td>-1.857301</td>\n",
       "      <td>0.048708</td>\n",
       "      <td>0.239436</td>\n",
       "      <td>0.174275</td>\n",
       "      <td>-0.246508</td>\n",
       "      <td>-1.356766</td>\n",
       "      <td>1.570377</td>\n",
       "      <td>0.461177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716355</td>\n",
       "      <td>0.927348</td>\n",
       "      <td>-1.945078</td>\n",
       "      <td>0.447272</td>\n",
       "      <td>2.082094</td>\n",
       "      <td>0.216941</td>\n",
       "      <td>-0.426031</td>\n",
       "      <td>0.944057</td>\n",
       "      <td>0.622310</td>\n",
       "      <td>-3.234755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34671 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1         2         3         4         5  \\\n",
       "subreddit                                                                     \n",
       "leagueoflegends -2.581650  4.197357 -0.414158 -4.637616 -1.270464  0.721880   \n",
       "theredlion      -5.078587  3.187933  1.306380  3.390276  0.009027  2.208565   \n",
       "inlandempire     1.787371  1.144207 -1.939735 -0.874147 -1.687357 -1.447701   \n",
       "nfl              1.324327  2.414587  2.463422  1.304439  5.792188  2.861849   \n",
       "playmygame       3.036528  0.657404  1.333009 -2.353914 -3.739832 -1.316537   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "mcchallenges     1.088152 -1.052172 -0.081496  0.599227  0.587108 -0.421348   \n",
       "zoomies          0.745022  0.203817 -1.079956 -1.680853  1.577193 -0.841061   \n",
       "asshole         -0.537883 -0.661029  0.098713 -0.808670  0.923758 -0.627248   \n",
       "dildohero       -0.249038 -0.996826  0.725330 -0.713229 -0.866005 -0.326092   \n",
       "ouija_irl        0.471297 -1.322305 -1.857301  0.048708  0.239436  0.174275   \n",
       "\n",
       "                        6         7         8         9  ...        54  \\\n",
       "subreddit                                                ...             \n",
       "leagueoflegends  3.302603  3.852562  0.082770  0.855891  ... -1.309510   \n",
       "theredlion       0.663524 -2.170339 -3.299234  4.855823  ... -0.704552   \n",
       "inlandempire    -2.463367  0.047332  3.669208 -5.642140  ...  1.381191   \n",
       "nfl              4.123739  1.847484 -2.223504  0.842010  ...  2.977067   \n",
       "playmygame       0.128526  0.776541 -3.212834 -0.607011  ... -1.821251   \n",
       "...                   ...       ...       ...       ...  ...       ...   \n",
       "mcchallenges    -0.328897 -0.444257  0.726301 -0.338954  ... -0.529689   \n",
       "zoomies         -0.916199  0.172354  0.699129  0.416368  ...  0.186617   \n",
       "asshole         -0.254959  0.508056  0.135096 -0.354623  ... -0.117812   \n",
       "dildohero       -0.751363 -1.660205  1.693578 -0.749767  ...  0.024560   \n",
       "ouija_irl       -0.246508 -1.356766  1.570377  0.461177  ...  0.716355   \n",
       "\n",
       "                       55        56        57        58        59        60  \\\n",
       "subreddit                                                                     \n",
       "leagueoflegends  2.200328 -0.537800 -0.944857 -3.069158  3.882328  4.642304   \n",
       "theredlion      -1.988924  1.746807  1.682895  0.917564 -2.376134  1.840948   \n",
       "inlandempire     1.326390  1.959474 -0.830282 -8.217797 -0.690313 -2.515662   \n",
       "nfl             -0.718431 -0.049687 -0.443616  2.430853 -0.791676  0.064785   \n",
       "playmygame      -0.415504 -3.183492  3.704080  2.105642 -5.455093  1.901566   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "mcchallenges     1.102415 -0.329409  0.948866 -0.232821 -1.136177  0.209243   \n",
       "zoomies          0.441517  1.469669  0.824215  1.754825 -0.493108  0.523124   \n",
       "asshole         -0.571725 -0.966365  0.951634  0.411589 -0.488988  0.083463   \n",
       "dildohero        0.254378  0.024955  0.659600  0.813747 -1.120681 -0.736590   \n",
       "ouija_irl        0.927348 -1.945078  0.447272  2.082094  0.216941 -0.426031   \n",
       "\n",
       "                       61        62        63  \n",
       "subreddit                                      \n",
       "leagueoflegends -4.706831 -1.937072  6.749583  \n",
       "theredlion       1.383271 -2.815420 -0.156633  \n",
       "inlandempire     0.354737 -0.242708 -0.834380  \n",
       "nfl             -1.367642  0.383723  5.842690  \n",
       "playmygame       1.531182 -0.390700  4.803727  \n",
       "...                   ...       ...       ...  \n",
       "mcchallenges     0.079921  1.184984 -0.558518  \n",
       "zoomies          0.050339  0.626424 -1.088371  \n",
       "asshole          1.102945 -1.133330 -0.873870  \n",
       "dildohero       -0.005955  0.421525 -1.350236  \n",
       "ouija_irl        0.944057  0.622310 -3.234755  \n",
       "\n",
       "[34671 rows x 64 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a82b28fc944966a4729914a6ba2c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=93696.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_gnn_embs = list()\n",
    "not_found_ids_train = list()\n",
    "for x in tqdm(flat_train_data[0]):\n",
    "    chunk = df_post_idx.loc[x]\n",
    "    if not isinstance(chunk,pd.core.series.Series):\n",
    "        source = chunk.SOURCE_SUBREDDIT.iloc[0]\n",
    "\n",
    "    else:\n",
    "        source = chunk.SOURCE_SUBREDDIT\n",
    "    try:\n",
    "        train_gnn_embs.append(df_emb.loc[source].values.tolist())\n",
    "    except KeyError:\n",
    "        not_found_ids_train.append(x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gnn_embeddings(ids_list):\n",
    "    gnn_embs = list()\n",
    "    not_found_ids = list()\n",
    "    for x in tqdm(ids_list):\n",
    "        chunk = df_post_idx.loc[x]\n",
    "        if not isinstance(chunk,pd.core.series.Series):\n",
    "            source = chunk.SOURCE_SUBREDDIT.iloc[0]\n",
    "\n",
    "        else:\n",
    "            source = chunk.SOURCE_SUBREDDIT\n",
    "        try:\n",
    "            gnn_embs.append((x,df_emb.loc[source].values.tolist()))\n",
    "        except KeyError:\n",
    "            not_found_ids.append(x)\n",
    "    return dict(gnn_embs),not_found_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4405b5cf6e9d4326ba85af0e94fd2555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=93696.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_gnn_embs,not_found_ids_train = get_gnn_embeddings(flat_train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0fa9022310b4782910cb36ff142ec36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11264.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_gnn_embs,not_found_ids_val = get_gnn_embeddings(flat_val_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f13436d6e7445d8ab4b7845b9a56de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11264.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_gnn_embs,not_found_ids_test = get_gnn_embeddings(flat_test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_X = np.stack([np.concatenate([meta_features[i], all_embeds[ids[i]], lstm_embeds[lstm_ids[i]]]) for i in flat_train_data[0] if (i not in not_found_ids_train)])\n",
    "val_X =  np.stack([np.concatenate([meta_features[i], all_embeds[ids[i]], lstm_embeds[lstm_ids[i]]]) for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_X =  np.stack([np.concatenate([meta_features[i],all_embeds[ids[i]], lstm_embeds[lstm_ids[i]]]) for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])\n",
    "\n",
    "train_Y = np.stack([meta_labels[i] for i in flat_train_data[0] if (i in meta_features) and (i not in not_found_ids_train)])\n",
    "val_Y =  np.stack([meta_labels[i] for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_Y =  np.stack([meta_labels[i] for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we run the Random Forest with only the metadata/handcrafted features...\n",
    "baseline_mod = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)\n",
    "# note that the first 263 features are the handcrafted ones... \n",
    "baseline_mod.fit(train_X[:, :263], train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6800026501149354\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(val_Y, baseline_mod.predict_proba(val_X[:, :263])[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6669488484136848"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_Y, baseline_mod.predict_proba(test_X[:, :263])[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# First we run the Random Forest with only the metadata/handcrafted features...\n",
    "ensemble_mod = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)\n",
    "# note that the first 263 features are the handcrafted ones... \n",
    "ensemble_mod.fit(train_X[:, :], train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7500665926317096"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(val_Y, ensemble_mod.predict_proba(val_X[:, :])[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_X = np.stack([np.concatenate([meta_features[i], all_embeds[ids[i]], lstm_embeds[lstm_ids[i]], train_gnn_embs[i]]) for i in flat_train_data[0] if (i not in not_found_ids_train)])\n",
    "val_X =  np.stack([np.concatenate([meta_features[i], all_embeds[ids[i]], lstm_embeds[lstm_ids[i]], val_gnn_embs[i]]) for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_X =  np.stack([np.concatenate([meta_features[i],all_embeds[ids[i]], lstm_embeds[lstm_ids[i]], test_gnn_embs[i]]) for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])\n",
    "\n",
    "train_Y = np.stack([meta_labels[i] for i in flat_train_data[0] if (i in meta_features) and (i not in not_found_ids_train)])\n",
    "val_Y =  np.stack([meta_labels[i] for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_Y =  np.stack([meta_labels[i] for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# First we run the Random Forest with only the metadata/handcrafted features...\n",
    "ensemble_mod = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)\n",
    "# note that the first 263 features are the handcrafted ones... \n",
    "ensemble_mod.fit(train_X[:, :], train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7498650674080517"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(val_Y, ensemble_mod.predict_proba(val_X[:, :])[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=700, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# First we run the Random Forest with only the metadata/handcrafted features...\n",
    "ensemble_mod = RandomForestClassifier(n_estimators=700, n_jobs=-1, random_state=0)\n",
    "# note that the first 263 features are the handcrafted ones... \n",
    "ensemble_mod.fit(train_X[:, :], train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7512728317594433"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(val_Y, ensemble_mod.predict_proba(val_X[:, :])[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_X = np.stack([np.concatenate([meta_features[i], all_embeds[ids[i]], train_gnn_embs[i]]) for i in flat_train_data[0] if (i not in not_found_ids_train)])\n",
    "val_X =  np.stack([np.concatenate([meta_features[i], all_embeds[ids[i]], val_gnn_embs[i]]) for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_X =  np.stack([np.concatenate([meta_features[i],all_embeds[ids[i]], test_gnn_embs[i]]) for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])\n",
    "\n",
    "train_Y = np.stack([meta_labels[i] for i in flat_train_data[0] if (i in meta_features) and (i not in not_found_ids_train)])\n",
    "val_Y =  np.stack([meta_labels[i] for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_Y =  np.stack([meta_labels[i] for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# First we run the Random Forest with only the metadata/handcrafted features...\n",
    "ensemble_mod = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)\n",
    "# note that the first 263 features are the handcrafted ones... \n",
    "ensemble_mod.fit(train_X[:, :], train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7597763031187873"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(val_Y, ensemble_mod.predict_proba(val_X[:, :])[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_X = np.stack([np.concatenate([meta_features[i], train_gnn_embs[i]]) for i in flat_train_data[0] if (i not in not_found_ids_train)])\n",
    "val_X =  np.stack([np.concatenate([meta_features[i], val_gnn_embs[i]]) for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_X =  np.stack([np.concatenate([meta_features[i], test_gnn_embs[i]]) for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])\n",
    "\n",
    "train_Y = np.stack([meta_labels[i] for i in flat_train_data[0] if (i in meta_features) and (i not in not_found_ids_train)])\n",
    "val_Y =  np.stack([meta_labels[i] for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_Y =  np.stack([meta_labels[i] for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# First we run the Random Forest with only the metadata/handcrafted features...\n",
    "ensemble_mod = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)\n",
    "# note that the first 263 features are the handcrafted ones... \n",
    "ensemble_mod.fit(train_X[:, :], train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7523408863226888"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(val_Y, ensemble_mod.predict_proba(val_X[:, :])[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_X = np.stack([np.concatenate([train_gnn_embs[i]]) for i in flat_train_data[0] if (i not in not_found_ids_train)])\n",
    "val_X =  np.stack([np.concatenate([val_gnn_embs[i]]) for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_X =  np.stack([np.concatenate([test_gnn_embs[i]]) for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])\n",
    "\n",
    "train_Y = np.stack([meta_labels[i] for i in flat_train_data[0] if (i in meta_features) and (i not in not_found_ids_train)])\n",
    "val_Y =  np.stack([meta_labels[i] for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_Y =  np.stack([meta_labels[i] for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# First we run the Random Forest with only the metadata/handcrafted features...\n",
    "ensemble_mod = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)\n",
    "# note that the first 263 features are the handcrafted ones... \n",
    "ensemble_mod.fit(train_X[:, :], train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7169973324117793"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(val_Y, ensemble_mod.predict_proba(val_X[:, :])[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256723, 900)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34671, 64)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emb.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_X = np.stack([np.concatenate([lstm_embeds[lstm_ids[i]]]) for i in flat_train_data[0] if (i not in not_found_ids_train)])\n",
    "val_X =  np.stack([np.concatenate([lstm_embeds[lstm_ids[i]]]) for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_X =  np.stack([np.concatenate([lstm_embeds[lstm_ids[i]]]) for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])\n",
    "\n",
    "train_Y = np.stack([meta_labels[i] for i in flat_train_data[0] if (i in meta_features) and (i not in not_found_ids_train)])\n",
    "val_Y =  np.stack([meta_labels[i] for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_Y =  np.stack([meta_labels[i] for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# First we run the Random Forest with only the metadata/handcrafted features...\n",
    "ensemble_mod = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)\n",
    "# note that the first 263 features are the handcrafted ones... \n",
    "ensemble_mod.fit(train_X[:, :], train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49259302582939857"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(val_Y, ensemble_mod.predict_proba(val_X[:, :])[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_X = np.stack([np.concatenate([all_embeds[ids[i]], train_gnn_embs[i]]) for i in flat_train_data[0] if (i not in not_found_ids_train)])\n",
    "val_X =  np.stack([np.concatenate([all_embeds[ids[i]], val_gnn_embs[i]]) for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_X =  np.stack([np.concatenate([all_embeds[ids[i]], test_gnn_embs[i]]) for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])\n",
    "\n",
    "train_Y = np.stack([meta_labels[i] for i in flat_train_data[0] if (i in meta_features) and (i not in not_found_ids_train)])\n",
    "val_Y =  np.stack([meta_labels[i] for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_Y =  np.stack([meta_labels[i] for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# First we run the Random Forest with only the metadata/handcrafted features...\n",
    "ensemble_mod = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)\n",
    "# note that the first 263 features are the handcrafted ones... \n",
    "ensemble_mod.fit(train_X[:, :], train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7449116337133449"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(val_Y, ensemble_mod.predict_proba(val_X[:, :])[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[meta_features[i], all_embeds[ids[i]], lstm_embeds[lstm_ids[i]], train_gnn_embs[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.744973129970179"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_X = np.stack([np.concatenate([all_embeds[ids[i]]]) for i in flat_train_data[0] if (i not in not_found_ids_train)])\n",
    "val_X =  np.stack([np.concatenate([all_embeds[ids[i]]]) for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_X =  np.stack([np.concatenate([all_embeds[ids[i]]]) for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])\n",
    "\n",
    "train_Y = np.stack([meta_labels[i] for i in flat_train_data[0] if (i in meta_features) and (i not in not_found_ids_train)])\n",
    "val_Y =  np.stack([meta_labels[i] for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_Y =  np.stack([meta_labels[i] for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])\n",
    "\n",
    "\n",
    "# First we run the Random Forest with only the metadata/handcrafted features...\n",
    "ensemble_mod = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)\n",
    "# note that the first 263 features are the handcrafted ones... \n",
    "ensemble_mod.fit(train_X[:, :], train_Y)\n",
    "roc_auc_score(val_Y, ensemble_mod.predict_proba(val_X[:, :])[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7440297667122266"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = np.stack([np.concatenate([all_embeds[ids[i]], lstm_embeds[lstm_ids[i]]]) for i in flat_train_data[0] if (i not in not_found_ids_train)])\n",
    "val_X =  np.stack([np.concatenate([all_embeds[ids[i]], lstm_embeds[lstm_ids[i]]]) for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_X =  np.stack([np.concatenate([all_embeds[ids[i]], lstm_embeds[lstm_ids[i]]]) for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])\n",
    "\n",
    "train_Y = np.stack([meta_labels[i] for i in flat_train_data[0] if (i in meta_features) and (i not in not_found_ids_train)])\n",
    "val_Y =  np.stack([meta_labels[i] for i in flat_val_data[0] if (i in meta_features) and (i not in not_found_ids_val)])\n",
    "test_Y =  np.stack([meta_labels[i] for i in flat_test_data[0] if (i in meta_features) and (i not in not_found_ids_test)])\n",
    "\n",
    "\n",
    "# First we run the Random Forest with only the metadata/handcrafted features...\n",
    "ensemble_mod = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)\n",
    "# note that the first 263 features are the handcrafted ones... \n",
    "ensemble_mod.fit(train_X[:, :], train_Y)\n",
    "roc_auc_score(val_Y, ensemble_mod.predict_proba(val_X[:, :])[:,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1 Datasets\n",
    "Dataset-1 D<sub>1,1</sub> = Only Meta-Features\n",
    "\n",
    "Dataset-2 D<sub>1,2</sub> = All embeddings\n",
    "\n",
    "Dataset-3 D<sub>1,3</sub> = LSTM-Embeddings\n",
    "\n",
    "Dataset-4 D<sub>1,4</sub> = Node2Vec-Embeddings\n",
    "\n",
    "## Level 2 Datasets\n",
    "Dataset-6 D<sub>2,3</sub> = All embeddings + LSTM-Embeddings\n",
    "\n",
    "Dataset-7 D<sub>2,4</sub> = All embeddings + Node2Vec-Embeddings\n",
    "\n",
    "## Level 3 Datasets\n",
    "Dataset-8 D<sub>3,3</sub> = All embeddings + Meta-Features + LSTM-Embeddings\n",
    "\n",
    "Dataset-8 D<sub>3,4</sub> = All embeddings + Meta-Features + Node2Vec-Embeddings\n",
    "\n",
    "## Complete\n",
    "Dataset-9 D<sub>4,3</sub> = All embeddings + Meta-Features + Node2Vec-Embeddings + LSTM-Embeddings\n",
    "\n",
    "\n",
    "| Dataset | ROC_AUC | Contains Graph Embedding |\n",
    "|---|---|---|\n",
    "|Level 1|||\n",
    "|Meta-Features| 0.6800 | No |\n",
    "|All embeddings| **0.7450** | No |\n",
    "|LSTM-Embeddings| 0.4926 | No |\n",
    "|Node2Vec-Embeddings| 0.7170 | Yes |\n",
    "|Level 2|||\n",
    "|All embeddings + LSTM-Embeddings| 0.7440 | No |\n",
    "|All embeddings + Node2Vec-Embeddings| 0.7450 | Yes |\n",
    "|Meta-Features + Node2Vec-Embeddings| **0.7523** | Yes |\n",
    "|Level 3|||\n",
    "All embeddings + Meta-Features + LSTM-Embeddings| 0.7501 | No |\n",
    "|All embeddings + Meta-Features + Node2Vec-Embeddings| **0.7598** | Yes |\n",
    "|Level 4|||\n",
    "|All available datasets| 0.7499 | No |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
